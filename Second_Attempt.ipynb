{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Create the folder\n",
        "# !mkdir -p \"/content/drive/MyDrive/kaggle_heart_disease\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV2tpZyPBlCE",
        "outputId": "429678b5-c169-4f99-81fd-d75186090d2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv('/content/drive/MyDrive/kaggle_heart_disease/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/kaggle_heart_disease/test.csv')\n",
        "sample_submission = pd.read_csv('/content/drive/MyDrive/kaggle_heart_disease/sample_submission.csv')\n",
        "\n",
        "print(f\"Train shape: {train.shape}\")\n",
        "print(f\"Test shape: {test.shape}\")\n",
        "print(f\"Sample submission shape: {sample_submission.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbEAs84U_tmv",
        "outputId": "af207e66-31fe-44c1-fc5e-d0406fb2d8c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (630000, 15)\n",
            "Test shape: (270000, 14)\n",
            "Sample submission shape: (270000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target\n",
        "train['Heart Disease'] = train['Heart Disease'].map({'Absence': 0, 'Presence': 1})\n",
        "X = train.drop(['id', 'Heart Disease'], axis=1)\n",
        "y = train['Heart Disease']\n",
        "\n",
        "# Keep test IDs for submission\n",
        "test_ids = test['id']\n",
        "X_test = test.drop(['id'], axis=1)"
      ],
      "metadata": {
        "id": "vj8Q5-t2CXaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = [\n",
        "    'Sex',                # binary\n",
        "    'Chest pain type',    # ordinal (1-4)\n",
        "    'FBS over 120',       # binary\n",
        "    'EKG results',        # ordinal (0-2)\n",
        "    'Exercise angina',    # binary\n",
        "    'Slope of ST',        # ordinal (1-3)\n",
        "    'Number of vessels fluro',  # ordinal (0-3)\n",
        "    'Thallium'            # ordinal (3,6,7)\n",
        "]\n",
        "\n",
        "numerical_features = [\n",
        "    'Age', 'BP', 'Cholesterol', 'Max HR', 'ST depression'\n",
        "]"
      ],
      "metadata": {
        "id": "-bG_x8fBCpsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8h6kbWygaOR",
        "outputId": "de6db69c-a9e5-44a4-ef80-903dd3afdd70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¥ LightGBM Fold 1\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[638]\tvalid_0's auc: 0.95562\n",
            "âœ… Fold 1 ROC AUC: 0.95562\n",
            "\n",
            "ðŸ”¥ LightGBM Fold 2\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[430]\tvalid_0's auc: 0.95462\n",
            "âœ… Fold 2 ROC AUC: 0.95462\n",
            "\n",
            "ðŸ”¥ LightGBM Fold 3\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[404]\tvalid_0's auc: 0.955391\n",
            "âœ… Fold 3 ROC AUC: 0.95539\n",
            "\n",
            "ðŸ”¥ LightGBM Fold 4\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[452]\tvalid_0's auc: 0.954927\n",
            "âœ… Fold 4 ROC AUC: 0.95493\n",
            "\n",
            "ðŸ”¥ LightGBM Fold 5\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[510]\tvalid_0's auc: 0.955754\n",
            "âœ… Fold 5 ROC AUC: 0.95575\n",
            "\n",
            "ðŸŽ¯ LightGBM CV: 0.95526 Â± 0.00043\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "lgb_cv_scores = []\n",
        "\n",
        "lgb_params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'auc',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'learning_rate': 0.05,\n",
        "    'num_leaves': 31,\n",
        "    'max_depth': -1,\n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'verbose': -1,\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1\n",
        "}\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "    print(f\"\\nðŸ”¥ LightGBM Fold {fold+1}\")\n",
        "\n",
        "    X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "    train_data = lgb.Dataset(X_tr, label=y_tr)\n",
        "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
        "\n",
        "    model = lgb.train(\n",
        "        lgb_params,\n",
        "        train_data,\n",
        "        num_boost_round=1000,\n",
        "        valid_sets=[val_data],\n",
        "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
        "    )\n",
        "\n",
        "    y_pred = model.predict(X_val)\n",
        "    auc = roc_auc_score(y_val, y_pred)\n",
        "    lgb_cv_scores.append(auc)\n",
        "    print(f\"âœ… Fold {fold+1} ROC AUC: {auc:.5f}\")\n",
        "\n",
        "print(f\"\\nðŸŽ¯ LightGBM CV: {np.mean(lgb_cv_scores):.5f} Â± {np.std(lgb_cv_scores):.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna --q\n",
        "\n",
        "import optuna\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Make sure X and y are loaded from previous cells\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 0.5),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 1, 3)\n",
        "    }\n",
        "\n",
        "    model = xgb.XGBClassifier(\n",
        "        **params,\n",
        "        n_estimators=500,                # fixed number (no early stopping needed)\n",
        "        eval_metric='auc',\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        use_label_encoder=False\n",
        "    )\n",
        "\n",
        "    score = np.mean(cross_val_score(model, X, y, cv=3, scoring='roc_auc'))\n",
        "    return score\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)   # 50 trials ~ 30-60 min depending on data size\n",
        "\n",
        "print(\"Best params:\", study.best_params)\n",
        "print(f\"Best CV: {study.best_value:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4SuBUC2i7A8",
        "outputId": "13e1a099-41b7-40c2-bf21-5baa4949a5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-15 14:57:33,306] A new study created in memory with name: no-name-06325500-5db1-4b71-8ba4-8a8ab735757e\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [14:57:33] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [14:57:50] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [14:58:08] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 14:58:25,030] Trial 0 finished with value: 0.9544167748435841 and parameters: {'learning_rate': 0.030078397152782127, 'max_depth': 3, 'subsample': 0.8979316099843415, 'colsample_bytree': 0.96369083753472, 'min_child_weight': 1, 'gamma': 0.17150569768456364, 'reg_alpha': 0.0799831791485398, 'reg_lambda': 1.724831391441907}. Best is trial 0 with value: 0.9544167748435841.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [14:58:25] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [14:58:50] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [14:59:15] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 14:59:38,902] Trial 1 finished with value: 0.955162084146584 and parameters: {'learning_rate': 0.07951182395069717, 'max_depth': 6, 'subsample': 0.8988397662980254, 'colsample_bytree': 0.7681271891615037, 'min_child_weight': 9, 'gamma': 0.3989745176092772, 'reg_alpha': 0.5132377664680523, 'reg_lambda': 2.8701533206094525}. Best is trial 1 with value: 0.955162084146584.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [14:59:39] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:00:22] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:01:05] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:01:49,243] Trial 2 finished with value: 0.9526038291949721 and parameters: {'learning_rate': 0.1064861814290655, 'max_depth': 10, 'subsample': 0.7300002896114015, 'colsample_bytree': 0.5653522440406814, 'min_child_weight': 3, 'gamma': 0.09598600732990892, 'reg_alpha': 0.832190015266155, 'reg_lambda': 2.2833733774603937}. Best is trial 1 with value: 0.955162084146584.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:01:50] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:02:28] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:03:10] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:03:45,469] Trial 3 finished with value: 0.9508863515468643 and parameters: {'learning_rate': 0.1944080576324339, 'max_depth': 9, 'subsample': 0.780561937129642, 'colsample_bytree': 0.5437870903858004, 'min_child_weight': 4, 'gamma': 0.004860390408182258, 'reg_alpha': 0.6386880442094482, 'reg_lambda': 2.0526916504100585}. Best is trial 1 with value: 0.955162084146584.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:03:46] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:04:14] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:04:41] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:05:07,394] Trial 4 finished with value: 0.9550239515384066 and parameters: {'learning_rate': 0.09635538759178852, 'max_depth': 6, 'subsample': 0.7788586225667061, 'colsample_bytree': 0.6710839609954198, 'min_child_weight': 2, 'gamma': 0.07748930257813463, 'reg_alpha': 0.26654923120003027, 'reg_lambda': 2.586788274780493}. Best is trial 1 with value: 0.955162084146584.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:05:07] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:05:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:06:21] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:06:56,314] Trial 5 finished with value: 0.9498973715932046 and parameters: {'learning_rate': 0.19218013314849772, 'max_depth': 9, 'subsample': 0.8599143996113113, 'colsample_bytree': 0.8545724732828262, 'min_child_weight': 5, 'gamma': 0.2557613897797071, 'reg_alpha': 0.015034704441082236, 'reg_lambda': 1.0752879218891112}. Best is trial 1 with value: 0.955162084146584.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:06:57] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:07:36] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:08:17] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:08:58,597] Trial 6 finished with value: 0.9489888121473293 and parameters: {'learning_rate': 0.17179103205250895, 'max_depth': 11, 'subsample': 0.8566899000714381, 'colsample_bytree': 0.7881463035088504, 'min_child_weight': 1, 'gamma': 0.41496907458376664, 'reg_alpha': 0.7075322309375273, 'reg_lambda': 2.114106259758098}. Best is trial 1 with value: 0.955162084146584.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:08:59] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:09:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:10:32] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:11:18,298] Trial 7 finished with value: 0.950198408041394 and parameters: {'learning_rate': 0.12795709173480438, 'max_depth': 10, 'subsample': 0.6756906736351105, 'colsample_bytree': 0.7528200742840628, 'min_child_weight': 1, 'gamma': 0.29479283387469013, 'reg_alpha': 0.2032945031133433, 'reg_lambda': 1.7256989657484305}. Best is trial 1 with value: 0.955162084146584.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:11:18] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:11:38] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:11:56] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:12:13,950] Trial 8 finished with value: 0.9553841742496488 and parameters: {'learning_rate': 0.13682116262553978, 'max_depth': 4, 'subsample': 0.8791103977323651, 'colsample_bytree': 0.613323237724408, 'min_child_weight': 9, 'gamma': 0.22378636137231012, 'reg_alpha': 0.7617300684872168, 'reg_lambda': 2.4279634466863067}. Best is trial 8 with value: 0.9553841742496488.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:12:14] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:12:42] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:13:11] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:13:39,056] Trial 9 finished with value: 0.9553244325299398 and parameters: {'learning_rate': 0.0493767469068876, 'max_depth': 6, 'subsample': 0.5659400171333349, 'colsample_bytree': 0.6024705904485134, 'min_child_weight': 10, 'gamma': 0.12703676281519016, 'reg_alpha': 0.4055777576312045, 'reg_lambda': 1.7569758836287646}. Best is trial 8 with value: 0.9553841742496488.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:13:39] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:13:56] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:14:12] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:14:28,726] Trial 10 finished with value: 0.9553625728675582 and parameters: {'learning_rate': 0.14097328063804374, 'max_depth': 3, 'subsample': 0.5161706717577462, 'colsample_bytree': 0.6532106879267585, 'min_child_weight': 8, 'gamma': 0.4958200557092849, 'reg_alpha': 0.856224153468226, 'reg_lambda': 2.957328213739638}. Best is trial 8 with value: 0.9553841742496488.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:14:29] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:14:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:14:59] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:15:13,521] Trial 11 finished with value: 0.9554391080403898 and parameters: {'learning_rate': 0.14511248832080478, 'max_depth': 3, 'subsample': 0.9791707872536015, 'colsample_bytree': 0.6594837669759438, 'min_child_weight': 8, 'gamma': 0.34185503976091797, 'reg_alpha': 0.9885835379347657, 'reg_lambda': 2.972315739150268}. Best is trial 11 with value: 0.9554391080403898.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:15:14] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:15:30] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:15:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:15:59,723] Trial 12 finished with value: 0.9554552760544576 and parameters: {'learning_rate': 0.1501651469422689, 'max_depth': 4, 'subsample': 0.984512922430979, 'colsample_bytree': 0.5068165993248022, 'min_child_weight': 7, 'gamma': 0.3314470999702477, 'reg_alpha': 0.9974681992572415, 'reg_lambda': 2.5372271353502223}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:16:00] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:16:16] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:16:30] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:16:45,097] Trial 13 finished with value: 0.9553750352347955 and parameters: {'learning_rate': 0.1626033897996838, 'max_depth': 5, 'subsample': 0.984810432645727, 'colsample_bytree': 0.5380461670269207, 'min_child_weight': 7, 'gamma': 0.33942984182095903, 'reg_alpha': 0.9929697306608617, 'reg_lambda': 2.668077934873067}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:16:46] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:17:00] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:17:14] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:17:28,344] Trial 14 finished with value: 0.9553510969857859 and parameters: {'learning_rate': 0.15951268400309268, 'max_depth': 4, 'subsample': 0.9913316103249266, 'colsample_bytree': 0.6842728615330268, 'min_child_weight': 6, 'gamma': 0.34705676662594875, 'reg_alpha': 0.9875796295372619, 'reg_lambda': 2.98751957452259}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:17:29] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:17:50] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:18:09] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:18:31,408] Trial 15 finished with value: 0.9551540726729032 and parameters: {'learning_rate': 0.1163860479604486, 'max_depth': 7, 'subsample': 0.9518157413885759, 'colsample_bytree': 0.510496791518193, 'min_child_weight': 7, 'gamma': 0.47076631133755154, 'reg_alpha': 0.9202133973455171, 'reg_lambda': 2.6852643643575784}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:18:31] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:18:49] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:19:07] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:19:27,232] Trial 16 finished with value: 0.955363608412482 and parameters: {'learning_rate': 0.07995252219748833, 'max_depth': 4, 'subsample': 0.939069630569361, 'colsample_bytree': 0.8556382501913725, 'min_child_weight': 6, 'gamma': 0.31920630980130693, 'reg_alpha': 0.5880551828719929, 'reg_lambda': 2.4375572707079827}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:19:27] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:19:44] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:20:00] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:20:16,184] Trial 17 finished with value: 0.9553868168048161 and parameters: {'learning_rate': 0.15024132734748027, 'max_depth': 3, 'subsample': 0.6531368637323973, 'colsample_bytree': 0.7015540389508857, 'min_child_weight': 8, 'gamma': 0.41124432629634666, 'reg_alpha': 0.8066083248021167, 'reg_lambda': 1.0452207731817562}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:20:16] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:20:39] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:21:00] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:21:21,257] Trial 18 finished with value: 0.9550413774383119 and parameters: {'learning_rate': 0.17146596842216028, 'max_depth': 5, 'subsample': 0.8184487122715469, 'colsample_bytree': 0.5995655989925501, 'min_child_weight': 10, 'gamma': 0.24435052767999887, 'reg_alpha': 0.38491892168162223, 'reg_lambda': 2.7619295063292055}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:21:22] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:21:43] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:22:06] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:22:29,426] Trial 19 finished with value: 0.9548104240032607 and parameters: {'learning_rate': 0.12485433355837924, 'max_depth': 8, 'subsample': 0.9514016921892198, 'colsample_bytree': 0.5004924345833678, 'min_child_weight': 7, 'gamma': 0.36996265931639166, 'reg_alpha': 0.9052384884614416, 'reg_lambda': 2.298106875383522}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:22:29] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:22:55] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:23:20] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:23:42,182] Trial 20 finished with value: 0.9536682032361513 and parameters: {'learning_rate': 0.08936247368340315, 'max_depth': 12, 'subsample': 0.998147161442182, 'colsample_bytree': 0.8290266759718289, 'min_child_weight': 5, 'gamma': 0.29485076139284266, 'reg_alpha': 0.6734012923032393, 'reg_lambda': 1.3503733882449152}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:23:42] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:23:59] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:24:16] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:24:31,955] Trial 21 finished with value: 0.9553706852011626 and parameters: {'learning_rate': 0.14971753590523149, 'max_depth': 3, 'subsample': 0.6326996508295624, 'colsample_bytree': 0.6902527556572315, 'min_child_weight': 8, 'gamma': 0.4378306738944796, 'reg_alpha': 0.7704598397218657, 'reg_lambda': 1.3792853829487524}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:24:32] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:24:49] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:25:06] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:25:22,289] Trial 22 finished with value: 0.9553055559920011 and parameters: {'learning_rate': 0.17681704776114013, 'max_depth': 3, 'subsample': 0.6698504450276336, 'colsample_bytree': 0.7148623957917204, 'min_child_weight': 8, 'gamma': 0.3807763808795013, 'reg_alpha': 0.9827354506301365, 'reg_lambda': 1.4402604330459965}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:25:22] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:25:46] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:26:08] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:26:31,725] Trial 23 finished with value: 0.9549971132058567 and parameters: {'learning_rate': 0.14725083834915892, 'max_depth': 5, 'subsample': 0.6221802019497167, 'colsample_bytree': 0.6330208611274273, 'min_child_weight': 9, 'gamma': 0.4459699383605662, 'reg_alpha': 0.8635074392157731, 'reg_lambda': 1.0509635114787215}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:26:32] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:26:50] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:27:09] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:27:29,942] Trial 24 finished with value: 0.9553179841465603 and parameters: {'learning_rate': 0.12100690957556881, 'max_depth': 4, 'subsample': 0.7043770807416849, 'colsample_bytree': 0.7247292484692219, 'min_child_weight': 7, 'gamma': 0.28824409625572905, 'reg_alpha': 0.7907244288096247, 'reg_lambda': 2.5042319529357076}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:27:30] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:27:46] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:28:03] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:28:19,623] Trial 25 finished with value: 0.9553019837131793 and parameters: {'learning_rate': 0.18427122813935315, 'max_depth': 3, 'subsample': 0.5931253913388899, 'colsample_bytree': 0.9233078014989186, 'min_child_weight': 8, 'gamma': 0.19644057005862614, 'reg_alpha': 0.9213099817254984, 'reg_lambda': 2.760828991076272}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:28:20] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:28:43] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:29:04] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:29:27,308] Trial 26 finished with value: 0.9550883994151663 and parameters: {'learning_rate': 0.15560499852054344, 'max_depth': 5, 'subsample': 0.8254453333568531, 'colsample_bytree': 0.5760824177339372, 'min_child_weight': 6, 'gamma': 0.3553206737007253, 'reg_alpha': 0.9393901701054431, 'reg_lambda': 2.2515165023783785}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:29:27] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:29:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:30:03] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:30:23,118] Trial 27 finished with value: 0.9553012854854215 and parameters: {'learning_rate': 0.13339512598515021, 'max_depth': 4, 'subsample': 0.9260362488773666, 'colsample_bytree': 0.803908080709881, 'min_child_weight': 9, 'gamma': 0.4122077942238856, 'reg_alpha': 0.7231753956163478, 'reg_lambda': 1.825850543764425}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:30:23] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:30:53] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:31:24] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:31:54,197] Trial 28 finished with value: 0.9541073392572437 and parameters: {'learning_rate': 0.1120265496871467, 'max_depth': 7, 'subsample': 0.5081217730977641, 'colsample_bytree': 0.7173039454416138, 'min_child_weight': 4, 'gamma': 0.32671612572904013, 'reg_alpha': 0.5869448148912723, 'reg_lambda': 1.5284380116647083}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:31:54] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:32:12] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:32:30] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:32:48,589] Trial 29 finished with value: 0.9541629964785242 and parameters: {'learning_rate': 0.022533729590036217, 'max_depth': 3, 'subsample': 0.9103581043929498, 'colsample_bytree': 0.9374938146047869, 'min_child_weight': 10, 'gamma': 0.1628898964551658, 'reg_alpha': 0.8356280250710403, 'reg_lambda': 1.9508563948328725}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:32:49] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:33:05] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:33:22] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:33:38,479] Trial 30 finished with value: 0.9550430609374766 and parameters: {'learning_rate': 0.05569974332546536, 'max_depth': 3, 'subsample': 0.7616514526380092, 'colsample_bytree': 0.6444101482879561, 'min_child_weight': 8, 'gamma': 0.2663994559432339, 'reg_alpha': 0.8945356723718446, 'reg_lambda': 1.2446289970254532}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:33:39] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:33:58] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:34:17] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:34:35,003] Trial 31 finished with value: 0.9554033381495165 and parameters: {'learning_rate': 0.13874442907390977, 'max_depth': 4, 'subsample': 0.8701418041877395, 'colsample_bytree': 0.5970192513204424, 'min_child_weight': 9, 'gamma': 0.20991011684845762, 'reg_alpha': 0.8164694436670029, 'reg_lambda': 2.4469564443496044}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:34:35] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:34:53] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:35:12] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:35:29,652] Trial 32 finished with value: 0.9553896691348877 and parameters: {'learning_rate': 0.14381195120813914, 'max_depth': 4, 'subsample': 0.9670845349045475, 'colsample_bytree': 0.5587612631053892, 'min_child_weight': 9, 'gamma': 0.19223992852327437, 'reg_alpha': 0.8032448570562397, 'reg_lambda': 2.8061750276756356}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:35:30] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:35:49] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:36:11] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:36:30,649] Trial 33 finished with value: 0.9551636977922793 and parameters: {'learning_rate': 0.16453922726908035, 'max_depth': 5, 'subsample': 0.9630998642706993, 'colsample_bytree': 0.5648340466058361, 'min_child_weight': 9, 'gamma': 0.20139339605176257, 'reg_alpha': 0.9602127013081279, 'reg_lambda': 2.8569613606682838}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:36:31] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:36:49] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:37:08] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:37:25,843] Trial 34 finished with value: 0.9554388654277507 and parameters: {'learning_rate': 0.14134807679415473, 'max_depth': 4, 'subsample': 0.8981030398768071, 'colsample_bytree': 0.5360182372587948, 'min_child_weight': 10, 'gamma': 0.15218228624663505, 'reg_alpha': 0.4595149665079487, 'reg_lambda': 2.831517417635431}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:37:26] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:37:51] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:38:14] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:38:40,226] Trial 35 finished with value: 0.9551828739007612 and parameters: {'learning_rate': 0.10669700917099693, 'max_depth': 6, 'subsample': 0.874688017488795, 'colsample_bytree': 0.5286095175173341, 'min_child_weight': 10, 'gamma': 0.14405320955405915, 'reg_alpha': 0.4555863444192999, 'reg_lambda': 2.559636317405637}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:38:40] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:38:58] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:39:17] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:39:34,907] Trial 36 finished with value: 0.9554056931972307 and parameters: {'learning_rate': 0.13245556425831007, 'max_depth': 4, 'subsample': 0.9164430956414462, 'colsample_bytree': 0.5950969955207593, 'min_child_weight': 10, 'gamma': 0.05257619817309536, 'reg_alpha': 0.2783063938536226, 'reg_lambda': 2.905283169418997}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:39:35] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:39:55] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:40:19] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:40:39,071] Trial 37 finished with value: 0.9554102139879013 and parameters: {'learning_rate': 0.09675008098215583, 'max_depth': 5, 'subsample': 0.9101698061042338, 'colsample_bytree': 0.5364308141416162, 'min_child_weight': 10, 'gamma': 0.04326185161091027, 'reg_alpha': 0.28265840631686145, 'reg_lambda': 2.909306221952796}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:40:39] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:41:06] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:41:32] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:41:56,600] Trial 38 finished with value: 0.9551832432894511 and parameters: {'learning_rate': 0.1001159096389291, 'max_depth': 6, 'subsample': 0.816946225574078, 'colsample_bytree': 0.5252385432118003, 'min_child_weight': 10, 'gamma': 0.051479337649111126, 'reg_alpha': 0.1991395265983263, 'reg_lambda': 2.6784717651303}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:41:57] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:42:18] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:42:39] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:43:01,304] Trial 39 finished with value: 0.9553955045275832 and parameters: {'learning_rate': 0.07268955053294807, 'max_depth': 5, 'subsample': 0.9031910900103359, 'colsample_bytree': 0.5531659925457217, 'min_child_weight': 7, 'gamma': 0.09762728023113768, 'reg_alpha': 0.3035377847556409, 'reg_lambda': 2.9930640709837144}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:43:01] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:43:30] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:43:58] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:44:25,152] Trial 40 finished with value: 0.9548786342666885 and parameters: {'learning_rate': 0.0860744066051692, 'max_depth': 7, 'subsample': 0.934076710282843, 'colsample_bytree': 0.6260783648934392, 'min_child_weight': 3, 'gamma': 0.010018127760819673, 'reg_alpha': 0.10548454800235468, 'reg_lambda': 2.860573031378605}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:44:25] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:44:45] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:45:03] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:45:21,805] Trial 41 finished with value: 0.9553961120813227 and parameters: {'learning_rate': 0.12669726927820832, 'max_depth': 4, 'subsample': 0.9115691583997945, 'colsample_bytree': 0.5802020183976615, 'min_child_weight': 10, 'gamma': 0.03563887468077484, 'reg_alpha': 0.3232140090908976, 'reg_lambda': 2.880803871433049}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:45:22] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:45:42] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:46:04] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:46:25,486] Trial 42 finished with value: 0.9553306766743489 and parameters: {'learning_rate': 0.11340561711166748, 'max_depth': 5, 'subsample': 0.8389967177293215, 'colsample_bytree': 0.522051912154631, 'min_child_weight': 10, 'gamma': 0.07535459039304931, 'reg_alpha': 0.22977375256687443, 'reg_lambda': 2.900513646688577}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:46:26] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:46:42] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:47:00] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:47:18,290] Trial 43 finished with value: 0.9552240899686243 and parameters: {'learning_rate': 0.1988090541510239, 'max_depth': 4, 'subsample': 0.9757442298277041, 'colsample_bytree': 0.6609595111336073, 'min_child_weight': 9, 'gamma': 0.10801220836689382, 'reg_alpha': 0.5140393767629841, 'reg_lambda': 2.586516549214806}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:47:19] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:47:34] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:47:49] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:48:04,202] Trial 44 finished with value: 0.9554264906491786 and parameters: {'learning_rate': 0.13275021189335517, 'max_depth': 3, 'subsample': 0.8934074784316799, 'colsample_bytree': 0.5482081055155322, 'min_child_weight': 10, 'gamma': 0.05670048545978029, 'reg_alpha': 0.14710551875883435, 'reg_lambda': 2.729459919305666}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:48:04] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:48:20] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:48:36] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:48:51,087] Trial 45 finished with value: 0.9553967668082356 and parameters: {'learning_rate': 0.09920201420992833, 'max_depth': 3, 'subsample': 0.8863358917523925, 'colsample_bytree': 0.501224055368216, 'min_child_weight': 9, 'gamma': 0.12112225403411096, 'reg_alpha': 0.13150591280073198, 'reg_lambda': 2.8020962777151612}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:48:51] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:49:07] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:49:24] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:49:40,433] Trial 46 finished with value: 0.9551934031214598 and parameters: {'learning_rate': 0.06770201465021126, 'max_depth': 3, 'subsample': 0.7880956890952131, 'colsample_bytree': 0.5503669721848669, 'min_child_weight': 5, 'gamma': 0.0069732462290539865, 'reg_alpha': 0.04926653314824214, 'reg_lambda': 2.6873627674112255}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:49:41] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:50:06] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:50:31] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:50:52,985] Trial 47 finished with value: 0.9548559963124572 and parameters: {'learning_rate': 0.15791568760856908, 'max_depth': 6, 'subsample': 0.9445771884426323, 'colsample_bytree': 0.5332521093916794, 'min_child_weight': 8, 'gamma': 0.07651208468940057, 'reg_alpha': 0.0007659426135833702, 'reg_lambda': 2.365608497309121}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:50:53] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:51:13] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:51:30] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:51:47,655] Trial 48 finished with value: 0.9545615886394981 and parameters: {'learning_rate': 0.16938067737815238, 'max_depth': 9, 'subsample': 0.9966650171334779, 'colsample_bytree': 0.5790593578633138, 'min_child_weight': 10, 'gamma': 0.15194041107745027, 'reg_alpha': 0.363027393004105, 'reg_lambda': 2.6283490237758254}. Best is trial 12 with value: 0.9554552760544576.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:51:48] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:52:03] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [15:52:19] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-15 15:52:34,462] Trial 49 finished with value: 0.9553697083730825 and parameters: {'learning_rate': 0.18498582954746484, 'max_depth': 3, 'subsample': 0.8543886937437934, 'colsample_bytree': 0.6200942751108196, 'min_child_weight': 9, 'gamma': 0.033765439094940945, 'reg_alpha': 0.15417350600149618, 'reg_lambda': 2.1054273581887637}. Best is trial 12 with value: 0.9554552760544576.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'learning_rate': 0.1501651469422689, 'max_depth': 4, 'subsample': 0.984512922430979, 'colsample_bytree': 0.5068165993248022, 'min_child_weight': 7, 'gamma': 0.3314470999702477, 'reg_alpha': 0.9974681992572415, 'reg_lambda': 2.5372271353502223}\n",
            "Best CV: 0.95546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = study.best_params.copy()\n",
        "best_params.pop('n_estimators', None)\n",
        "best_params['n_estimators'] = 1000  # we'll use early stopping to find optimal number\n",
        "\n",
        "final_model = xgb.XGBClassifier(\n",
        "    **best_params,\n",
        "    early_stopping_rounds=50,\n",
        "    eval_metric='auc',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# We need an eval_set for early stopping â€” split a small validation set from training\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
        "\n",
        "final_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "print(f\"Best iteration: {final_model.best_iteration}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "Z2TcUffUCkH6",
        "outputId": "01fcc0c7-6432-4f7f-b49c-2a75d7550eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'study' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-31306026.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m  \u001b[0;31m# we'll use early stopping to find optimal number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m final_model = xgb.XGBClassifier(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'study' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrain on full data with best_iteration trees\n",
        "final_model_full = xgb.XGBClassifier(\n",
        "    **best_params,\n",
        "    n_estimators=final_model.best_iteration,  # use the optimal number found\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "final_model_full.fit(X, y)\n",
        "\n",
        "test_preds = final_model_full.predict_proba(X_test)[:, 1]\n",
        "\n",
        "submission = pd.DataFrame({'id': test_ids, 'Heart Disease': test_preds})\n",
        "submission.to_csv('optuna_tuned_submission.csv', index=False)\n",
        "\n",
        "from google.colab import files\n",
        "files.download('optuna_tuned_submission.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "PUsnxrCRCzaH",
        "outputId": "3c278602-ddbd-454d-a9f2-bbf742bde5da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "xgboost.sklearn.XGBClassifier() got multiple values for keyword argument 'n_estimators'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-600995047.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Retrain on full data with best_iteration trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m final_model_full = xgb.XGBClassifier(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# use the optimal number found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: xgboost.sklearn.XGBClassifier() got multiple values for keyword argument 'n_estimators'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # From your correlation list:\n",
        "# top_features = ['Thallium', 'Chest pain type', 'Exercise angina',\n",
        "#                 'Number of vessels fluro', 'ST depression', 'Slope of ST', 'Max HR']\n",
        "\n",
        "# # Interactions (multiplicative)\n",
        "# X['thal_x_chest'] = X['Thallium'] * X['Chest pain type']\n",
        "# X['exang_x_vessels'] = X['Exercise angina'] * X['Number of vessels fluro']\n",
        "# X['stdep_x_slope'] = X['ST depression'] * X['Slope of ST']\n",
        "# X['age_x_maxhr'] = X['Age'] * X['Max HR']\n",
        "\n",
        "# # Ratios (if denominator > 0)\n",
        "# X['bp_per_age'] = X['BP'] / (X['Age'] + 1)\n",
        "# X['chol_per_age'] = X['Cholesterol'] / (X['Age'] + 1)\n",
        "\n",
        "# # Polynomials (degree=2) for top 3\n",
        "# from sklearn.preprocessing import PolynomialFeatures\n",
        "# poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)\n",
        "# top3 = X[['Thallium', 'Chest pain type', 'Exercise angina']]\n",
        "# poly_features = poly.fit_transform(top3)\n",
        "# poly_df = pd.DataFrame(poly_features, columns=poly.get_feature_names_out(top3.columns))\n",
        "# X = pd.concat([X, poly_df], axis=1)"
      ],
      "metadata": {
        "id": "giwX9jiYi8Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Train both on full data with best params\n",
        "# xgb_final = xgb.XGBClassifier(**best_xgb_params, n_estimators=1000,\n",
        "#                               early_stopping_rounds=50, random_state=42)\n",
        "# xgb_final.fit(X, y, eval_set=[(X, y)], verbose=False)\n",
        "\n",
        "# lgb_final = lgb.LGBMClassifier(**best_lgb_params, n_estimators=1000,\n",
        "#                                early_stopping_rounds=50, random_state=42)\n",
        "# lgb_final.fit(X, y, eval_set=[(X, y)], verbose=False)\n",
        "\n",
        "# # Predict\n",
        "# xgb_preds = xgb_final.predict_proba(X_test)[:, 1]\n",
        "# lgb_preds = lgb_final.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# # Simple average\n",
        "# ensemble_preds = (xgb_preds + lgb_preds) / 2\n",
        "\n",
        "# submission = pd.DataFrame({'id': test_ids, 'Heart Disease': ensemble_preds})\n",
        "# submission.to_csv('ensemble_xgb_lgb.csv', index=False)"
      ],
      "metadata": {
        "id": "SMznwOyRjIcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.ensemble import StackingClassifier\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# import catboost as cb\n",
        "\n",
        "# base_models = [\n",
        "#     ('xgb', xgb.XGBClassifier(n_estimators=500, learning_rate=0.05, max_depth=6, random_state=42)),\n",
        "#     ('lgb', lgb.LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=31, random_state=42)),\n",
        "#     ('cb', cb.CatBoostClassifier(iterations=500, learning_rate=0.05, verbose=0, random_state=42))\n",
        "# ]\n",
        "\n",
        "# stack = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression(), cv=5)\n",
        "# stack.fit(X, y)\n",
        "# stack_preds = stack.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# submission['Heart Disease'] = stack_preds\n",
        "# submission.to_csv('stacking_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "7IgRLhOsjNtO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}