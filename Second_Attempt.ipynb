{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Create the folder\n",
        "# !mkdir -p \"/content/drive/MyDrive/kaggle_heart_disease\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV2tpZyPBlCE",
        "outputId": "d8a98bcf-796a-47e4-e374-a1ffecd9ea54"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv('/content/drive/MyDrive/kaggle_heart_disease/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/kaggle_heart_disease/test.csv')\n",
        "sample_submission = pd.read_csv('/content/drive/MyDrive/kaggle_heart_disease/sample_submission.csv')\n",
        "\n",
        "print(f\"Train shape: {train.shape}\")\n",
        "print(f\"Test shape: {test.shape}\")\n",
        "print(f\"Sample submission shape: {sample_submission.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbEAs84U_tmv",
        "outputId": "464bca8c-e157-42ba-b282-a317322645e0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (630000, 15)\n",
            "Test shape: (270000, 14)\n",
            "Sample submission shape: (270000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target\n",
        "train['Heart Disease'] = train['Heart Disease'].map({'Absence': 0, 'Presence': 1})\n",
        "X = train.drop(['id', 'Heart Disease'], axis=1)\n",
        "y = train['Heart Disease']\n",
        "\n",
        "# Keep test IDs for submission\n",
        "test_ids = test['id']\n",
        "X_test = test.drop(['id'], axis=1)"
      ],
      "metadata": {
        "id": "vj8Q5-t2CXaN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = [\n",
        "    'Sex',                # binary\n",
        "    'Chest pain type',    # ordinal (1-4)\n",
        "    'FBS over 120',       # binary\n",
        "    'EKG results',        # ordinal (0-2)\n",
        "    'Exercise angina',    # binary\n",
        "    'Slope of ST',        # ordinal (1-3)\n",
        "    'Number of vessels fluro',  # ordinal (0-3)\n",
        "    'Thallium'            # ordinal (3,6,7)\n",
        "]\n",
        "\n",
        "numerical_features = [\n",
        "    'Age', 'BP', 'Cholesterol', 'Max HR', 'ST depression'\n",
        "]"
      ],
      "metadata": {
        "id": "-bG_x8fBCpsI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8h6kbWygaOR",
        "outputId": "52cdde4e-ba80-439c-b9ee-65d24120887b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üî• LightGBM Fold 1\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[638]\tvalid_0's auc: 0.95562\n",
            "‚úÖ Fold 1 ROC AUC: 0.95562\n",
            "\n",
            "üî• LightGBM Fold 2\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[430]\tvalid_0's auc: 0.95462\n",
            "‚úÖ Fold 2 ROC AUC: 0.95462\n",
            "\n",
            "üî• LightGBM Fold 3\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[404]\tvalid_0's auc: 0.955391\n",
            "‚úÖ Fold 3 ROC AUC: 0.95539\n",
            "\n",
            "üî• LightGBM Fold 4\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[452]\tvalid_0's auc: 0.954927\n",
            "‚úÖ Fold 4 ROC AUC: 0.95493\n",
            "\n",
            "üî• LightGBM Fold 5\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[510]\tvalid_0's auc: 0.955754\n",
            "‚úÖ Fold 5 ROC AUC: 0.95575\n",
            "\n",
            "üéØ LightGBM CV: 0.95526 ¬± 0.00043\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "lgb_cv_scores = []\n",
        "\n",
        "lgb_params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'auc',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'learning_rate': 0.05,\n",
        "    'num_leaves': 31,\n",
        "    'max_depth': -1,\n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'verbose': -1,\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1\n",
        "}\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "    print(f\"\\nüî• LightGBM Fold {fold+1}\")\n",
        "\n",
        "    X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "    train_data = lgb.Dataset(X_tr, label=y_tr)\n",
        "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
        "\n",
        "    model = lgb.train(\n",
        "        lgb_params,\n",
        "        train_data,\n",
        "        num_boost_round=1000,\n",
        "        valid_sets=[val_data],\n",
        "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
        "    )\n",
        "\n",
        "    y_pred = model.predict(X_val)\n",
        "    auc = roc_auc_score(y_val, y_pred)\n",
        "    lgb_cv_scores.append(auc)\n",
        "    print(f\"‚úÖ Fold {fold+1} ROC AUC: {auc:.5f}\")\n",
        "\n",
        "print(f\"\\nüéØ LightGBM CV: {np.mean(lgb_cv_scores):.5f} ¬± {np.std(lgb_cv_scores):.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna --q\n",
        "\n",
        "import optuna\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Make sure X and y are loaded from previous cells\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'gamma': trial.suggest_float('gamma', 0, 0.5),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 1, 3)\n",
        "    }\n",
        "\n",
        "    model = xgb.XGBClassifier(\n",
        "        **params,\n",
        "        n_estimators=500,                # fixed number (no early stopping needed)\n",
        "        eval_metric='auc',\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        use_label_encoder=False\n",
        "    )\n",
        "\n",
        "    score = np.mean(cross_val_score(model, X, y, cv=3, scoring='roc_auc'))\n",
        "    return score\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)   # 50 trials ~ 30-60 min depending on data size\n",
        "\n",
        "print(\"Best params:\", study.best_params)\n",
        "print(f\"Best CV: {study.best_value:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4SuBUC2i7A8",
        "outputId": "765e8f4f-40ba-4330-e8d9-0d2e81c97eb1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/413.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m413.9/413.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-20 22:29:47,632] A new study created in memory with name: no-name-e479f5c9-6fdf-4328-9b4a-a7c61364ea47\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:29:48] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:30:08] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:30:30] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:30:49,878] Trial 0 finished with value: 0.9543074471980949 and parameters: {'learning_rate': 0.08964923804749991, 'max_depth': 7, 'subsample': 0.6846380107463494, 'colsample_bytree': 0.9748432020772209, 'min_child_weight': 2, 'gamma': 0.13588958543443913, 'reg_alpha': 0.18100612007058803, 'reg_lambda': 1.1143749620200922}. Best is trial 0 with value: 0.9543074471980949.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:30:50] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:31:09] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:31:27] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:31:44,160] Trial 1 finished with value: 0.9552723897403004 and parameters: {'learning_rate': 0.04739523303499548, 'max_depth': 5, 'subsample': 0.6227009975923593, 'colsample_bytree': 0.7275343816200037, 'min_child_weight': 3, 'gamma': 0.4737997753358757, 'reg_alpha': 0.9665901609113298, 'reg_lambda': 1.062717177686145}. Best is trial 1 with value: 0.9552723897403004.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:31:44] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:32:17] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:32:49] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:33:20,492] Trial 2 finished with value: 0.952053486372308 and parameters: {'learning_rate': 0.06877476831527922, 'max_depth': 11, 'subsample': 0.6307306510712694, 'colsample_bytree': 0.770556072300738, 'min_child_weight': 2, 'gamma': 0.3683881802294223, 'reg_alpha': 0.19167714235809674, 'reg_lambda': 1.3714722087386297}. Best is trial 1 with value: 0.9552723897403004.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:33:20] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:33:36] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:33:51] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:34:06,433] Trial 3 finished with value: 0.955321365421466 and parameters: {'learning_rate': 0.11773340226083423, 'max_depth': 4, 'subsample': 0.6666489265425523, 'colsample_bytree': 0.6875087301780047, 'min_child_weight': 9, 'gamma': 0.14828640654892622, 'reg_alpha': 0.9743601633335256, 'reg_lambda': 1.0968666781901983}. Best is trial 3 with value: 0.955321365421466.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:34:07] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:34:25] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:34:43] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:35:03,900] Trial 4 finished with value: 0.9551368052976456 and parameters: {'learning_rate': 0.05339842214784438, 'max_depth': 6, 'subsample': 0.7697051388599305, 'colsample_bytree': 0.9607347943268063, 'min_child_weight': 3, 'gamma': 0.4574988984913734, 'reg_alpha': 0.480973079784361, 'reg_lambda': 2.4448232649028308}. Best is trial 3 with value: 0.955321365421466.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:35:04] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:35:35] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:36:05] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:36:36,043] Trial 5 finished with value: 0.9533011375008232 and parameters: {'learning_rate': 0.07011385400131219, 'max_depth': 11, 'subsample': 0.6838504517852989, 'colsample_bytree': 0.5747894811608714, 'min_child_weight': 1, 'gamma': 0.45382679937940307, 'reg_alpha': 0.9392157585994181, 'reg_lambda': 1.558251522468214}. Best is trial 3 with value: 0.955321365421466.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:36:36] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:37:01] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:37:27] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:37:53,547] Trial 6 finished with value: 0.9549863700211967 and parameters: {'learning_rate': 0.035589800007571185, 'max_depth': 9, 'subsample': 0.8880816812696994, 'colsample_bytree': 0.6234370731953911, 'min_child_weight': 1, 'gamma': 0.10766340709021738, 'reg_alpha': 0.4927355772959622, 'reg_lambda': 2.754481828957612}. Best is trial 3 with value: 0.955321365421466.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:37:53] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:38:15] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:38:30] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:38:46,332] Trial 7 finished with value: 0.9549947524402299 and parameters: {'learning_rate': 0.19219023051856313, 'max_depth': 5, 'subsample': 0.8726736875239107, 'colsample_bytree': 0.5268910312139593, 'min_child_weight': 4, 'gamma': 0.13985700392700673, 'reg_alpha': 0.9685902154797749, 'reg_lambda': 1.5027056986400567}. Best is trial 3 with value: 0.955321365421466.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:38:46] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:39:02] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:39:17] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:39:33,277] Trial 8 finished with value: 0.9550094911164279 and parameters: {'learning_rate': 0.1831107804177278, 'max_depth': 4, 'subsample': 0.6239163409276662, 'colsample_bytree': 0.989609857314725, 'min_child_weight': 7, 'gamma': 0.3248295457430321, 'reg_alpha': 0.8368143205405572, 'reg_lambda': 2.1438051912677376}. Best is trial 3 with value: 0.955321365421466.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:39:34] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:39:52] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:40:09] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:40:25,736] Trial 9 finished with value: 0.9551637441527056 and parameters: {'learning_rate': 0.09525520257579093, 'max_depth': 5, 'subsample': 0.61997727928034, 'colsample_bytree': 0.8180058374585499, 'min_child_weight': 7, 'gamma': 0.36353988879873383, 'reg_alpha': 0.7341787546107615, 'reg_lambda': 1.682576546145939}. Best is trial 3 with value: 0.955321365421466.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:40:26] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:40:40] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:40:54] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:41:08,200] Trial 10 finished with value: 0.9553437774423643 and parameters: {'learning_rate': 0.13845207068021403, 'max_depth': 3, 'subsample': 0.5158530621697112, 'colsample_bytree': 0.6881265800629198, 'min_child_weight': 10, 'gamma': 0.03467362820652106, 'reg_alpha': 0.6588902594365375, 'reg_lambda': 1.968099772683884}. Best is trial 10 with value: 0.9553437774423643.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:41:08] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:41:23] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:41:37] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:41:50,696] Trial 11 finished with value: 0.9553283460798215 and parameters: {'learning_rate': 0.14015216300896866, 'max_depth': 3, 'subsample': 0.5027397875174425, 'colsample_bytree': 0.6734346307213526, 'min_child_weight': 10, 'gamma': 0.06221159206449073, 'reg_alpha': 0.6664580381380101, 'reg_lambda': 2.9518828288587575}. Best is trial 10 with value: 0.9553437774423643.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:41:51] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:42:05] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:42:19] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:42:32,574] Trial 12 finished with value: 0.9553489947206432 and parameters: {'learning_rate': 0.1479454085431399, 'max_depth': 3, 'subsample': 0.5027788921289474, 'colsample_bytree': 0.6644974729232425, 'min_child_weight': 10, 'gamma': 0.025707932007162343, 'reg_alpha': 0.6170543951548773, 'reg_lambda': 2.891754708096118}. Best is trial 12 with value: 0.9553489947206432.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:42:33] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:42:47] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:43:00] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:43:14,072] Trial 13 finished with value: 0.9553409015120494 and parameters: {'learning_rate': 0.15066543025241239, 'max_depth': 3, 'subsample': 0.5047683529257054, 'colsample_bytree': 0.8373672707655397, 'min_child_weight': 8, 'gamma': 0.00750024366611704, 'reg_alpha': 0.3618307791790556, 'reg_lambda': 2.072284434931391}. Best is trial 12 with value: 0.9553489947206432.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:43:14] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:43:40] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:44:06] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:44:33,398] Trial 14 finished with value: 0.9522831747120434 and parameters: {'learning_rate': 0.15611157547704207, 'max_depth': 9, 'subsample': 0.5535657806674791, 'colsample_bytree': 0.6147272389743271, 'min_child_weight': 10, 'gamma': 0.24337259845525994, 'reg_alpha': 0.6457688540834352, 'reg_lambda': 2.4058960976583643}. Best is trial 12 with value: 0.9553489947206432.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:44:33] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:44:47] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:45:00] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:45:12,861] Trial 15 finished with value: 0.9554431031835063 and parameters: {'learning_rate': 0.12736658617430152, 'max_depth': 3, 'subsample': 0.7906713467976316, 'colsample_bytree': 0.5017118684488431, 'min_child_weight': 6, 'gamma': 0.0031312003414666403, 'reg_alpha': 0.36856560109992176, 'reg_lambda': 1.8230222038381347}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:45:13] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:45:33] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:45:53] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:46:11,807] Trial 16 finished with value: 0.9546096582569827 and parameters: {'learning_rate': 0.11806034973501567, 'max_depth': 7, 'subsample': 0.8038553623863115, 'colsample_bytree': 0.5110942868161577, 'min_child_weight': 5, 'gamma': 0.21860324989215452, 'reg_alpha': 0.34037489237329926, 'reg_lambda': 1.7777111963141343}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:46:12] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:46:42] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:47:11] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:47:39,851] Trial 17 finished with value: 0.9547915435516874 and parameters: {'learning_rate': 0.011676199832853063, 'max_depth': 9, 'subsample': 0.8088109007566782, 'colsample_bytree': 0.5601811792973628, 'min_child_weight': 6, 'gamma': 0.06926869099805863, 'reg_alpha': 0.08921553324285447, 'reg_lambda': 2.623904746432459}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:47:40] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:47:53] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:48:07] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:48:19,824] Trial 18 finished with value: 0.9551831845801818 and parameters: {'learning_rate': 0.17228875940096053, 'max_depth': 4, 'subsample': 0.939617464446022, 'colsample_bytree': 0.9063588253481765, 'min_child_weight': 8, 'gamma': 0.0016275315682164602, 'reg_alpha': 0.3720520832421774, 'reg_lambda': 2.2864645026229953}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:48:20] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:48:35] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:48:50] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:49:05,707] Trial 19 finished with value: 0.9550480272781617 and parameters: {'learning_rate': 0.11648091302064238, 'max_depth': 6, 'subsample': 0.9824842821195313, 'colsample_bytree': 0.6229815291678245, 'min_child_weight': 5, 'gamma': 0.17548204996779934, 'reg_alpha': 0.5522712439585774, 'reg_lambda': 1.8590155592239928}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:49:06] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:49:19] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:49:32] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:49:45,011] Trial 20 finished with value: 0.9553132954069982 and parameters: {'learning_rate': 0.17212094539454195, 'max_depth': 3, 'subsample': 0.7197655315927453, 'colsample_bytree': 0.7545198978877184, 'min_child_weight': 6, 'gamma': 0.08154254360048874, 'reg_alpha': 0.2479724864518726, 'reg_lambda': 2.940432273944344}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:49:45] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:49:59] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:50:13] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:50:26,712] Trial 21 finished with value: 0.9553601627970516 and parameters: {'learning_rate': 0.1352079076246892, 'max_depth': 3, 'subsample': 0.5564661578941036, 'colsample_bytree': 0.6743495382227822, 'min_child_weight': 9, 'gamma': 0.03653687261249847, 'reg_alpha': 0.5889629176116078, 'reg_lambda': 1.9868043126534778}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:50:27] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:50:41] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:50:55] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:51:09,059] Trial 22 finished with value: 0.9553591190151415 and parameters: {'learning_rate': 0.1333370293468913, 'max_depth': 3, 'subsample': 0.5651116203361057, 'colsample_bytree': 0.6536529873019024, 'min_child_weight': 9, 'gamma': 0.03398272496044926, 'reg_alpha': 0.5604832287413897, 'reg_lambda': 2.211659174845063}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:51:09] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:51:25] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:51:40] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:51:57,983] Trial 23 finished with value: 0.9553142710447547 and parameters: {'learning_rate': 0.1290505299381152, 'max_depth': 4, 'subsample': 0.5731582388267598, 'colsample_bytree': 0.5846725061406617, 'min_child_weight': 8, 'gamma': 0.09875811972890691, 'reg_alpha': 0.45444270386438607, 'reg_lambda': 2.2227475114386186}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:51:58] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:52:15] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:52:33] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:52:50,524] Trial 24 finished with value: 0.9552980965610027 and parameters: {'learning_rate': 0.10064271641754553, 'max_depth': 5, 'subsample': 0.5735019519013133, 'colsample_bytree': 0.5017406609212612, 'min_child_weight': 9, 'gamma': 0.19804136326030042, 'reg_alpha': 0.7705205168769942, 'reg_lambda': 1.924568134412912}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:52:51] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:53:25] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:53:59] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:54:33,878] Trial 25 finished with value: 0.9477014803418998 and parameters: {'learning_rate': 0.1620945569519446, 'max_depth': 12, 'subsample': 0.7418095472626124, 'colsample_bytree': 0.7260256794878878, 'min_child_weight': 7, 'gamma': 0.05219003915833001, 'reg_alpha': 0.5711324252178948, 'reg_lambda': 2.392351141210575}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:54:34] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:54:51] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:55:10] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:55:27,932] Trial 26 finished with value: 0.9546416904550261 and parameters: {'learning_rate': 0.13028692756042792, 'max_depth': 6, 'subsample': 0.830052511821592, 'colsample_bytree': 0.79028187396148, 'min_child_weight': 9, 'gamma': 0.2827589303250332, 'reg_alpha': 0.420062357893381, 'reg_lambda': 1.7215194349168652}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:55:28] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:55:44] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:55:59] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:56:15,116] Trial 27 finished with value: 0.9552621127435161 and parameters: {'learning_rate': 0.11053151975966784, 'max_depth': 4, 'subsample': 0.5528071462432519, 'colsample_bytree': 0.8689548128581188, 'min_child_weight': 8, 'gamma': 0.11008664603768377, 'reg_alpha': 0.28460913285791845, 'reg_lambda': 2.0504367918822575}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:56:15] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:56:39] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:57:02] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:57:23,289] Trial 28 finished with value: 0.954448493830272 and parameters: {'learning_rate': 0.08625910338078505, 'max_depth': 8, 'subsample': 0.719080392464241, 'colsample_bytree': 0.6442797571131543, 'min_child_weight': 9, 'gamma': 0.04199005758365207, 'reg_alpha': 0.031246909273214385, 'reg_lambda': 2.5603611345641784}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:57:23] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:57:46] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:58:07] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:58:28,661] Trial 29 finished with value: 0.9548772729606032 and parameters: {'learning_rate': 0.08209614559075666, 'max_depth': 7, 'subsample': 0.6526181222943439, 'colsample_bytree': 0.5491801228589454, 'min_child_weight': 6, 'gamma': 0.1613016842626505, 'reg_alpha': 0.5692436938921347, 'reg_lambda': 1.593589796996645}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:58:29] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:58:43] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:58:57] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:59:10,800] Trial 30 finished with value: 0.9553729743869322 and parameters: {'learning_rate': 0.13013895899001596, 'max_depth': 3, 'subsample': 0.5872358572547353, 'colsample_bytree': 0.5888744221117574, 'min_child_weight': 7, 'gamma': 0.12477593917767629, 'reg_alpha': 0.7533533734850357, 'reg_lambda': 1.2391785227630927}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:59:11] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:59:25] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:59:39] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 22:59:52,933] Trial 31 finished with value: 0.9553841142760446 and parameters: {'learning_rate': 0.1292996838771053, 'max_depth': 3, 'subsample': 0.5955384395739934, 'colsample_bytree': 0.589729207773081, 'min_child_weight': 7, 'gamma': 0.11289732337914549, 'reg_alpha': 0.8251125476534564, 'reg_lambda': 1.2888730844962524}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [22:59:53] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:00:08] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:00:25] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 23:00:41,366] Trial 32 finished with value: 0.955341037678615 and parameters: {'learning_rate': 0.12385180202110514, 'max_depth': 4, 'subsample': 0.5889787350329817, 'colsample_bytree': 0.602211974642891, 'min_child_weight': 7, 'gamma': 0.11495361503570878, 'reg_alpha': 0.8730409843964668, 'reg_lambda': 1.3510311139708495}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:00:41] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:00:55] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:01:09] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 23:01:23,477] Trial 33 finished with value: 0.955344107780255 and parameters: {'learning_rate': 0.10233461105337412, 'max_depth': 3, 'subsample': 0.6062975328454526, 'colsample_bytree': 0.5417505882888366, 'min_child_weight': 5, 'gamma': 0.07889641028777461, 'reg_alpha': 0.7202991229447555, 'reg_lambda': 1.2458848900675772}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:01:23] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:01:41] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:01:58] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 23:02:17,675] Trial 34 finished with value: 0.9550103918807156 and parameters: {'learning_rate': 0.14393681559556068, 'max_depth': 5, 'subsample': 0.5341673094513391, 'colsample_bytree': 0.5871808437351327, 'min_child_weight': 4, 'gamma': 0.004490297842920412, 'reg_alpha': 0.8278917420328428, 'reg_lambda': 1.2984311968673605}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:02:18] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:02:33] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:02:48] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 23:03:03,470] Trial 35 finished with value: 0.955310014995795 and parameters: {'learning_rate': 0.16519642533151754, 'max_depth': 4, 'subsample': 0.6532637270229219, 'colsample_bytree': 0.5303001424238355, 'min_child_weight': 6, 'gamma': 0.12812437606324062, 'reg_alpha': 0.9011554102542854, 'reg_lambda': 1.0376999085510263}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:03:03] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:03:20] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:03:37] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 23:03:55,064] Trial 36 finished with value: 0.9551423169724456 and parameters: {'learning_rate': 0.10955232856519369, 'max_depth': 5, 'subsample': 0.7043550208689588, 'colsample_bytree': 0.7261673682301921, 'min_child_weight': 7, 'gamma': 0.17442527456155477, 'reg_alpha': 0.7665903062152263, 'reg_lambda': 1.1840808763563395}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:03:55] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:04:08] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:04:24] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 23:04:37,640] Trial 37 finished with value: 0.9554051176860328 and parameters: {'learning_rate': 0.12459537313566306, 'max_depth': 3, 'subsample': 0.7741254574823901, 'colsample_bytree': 0.7052844570845406, 'min_child_weight': 4, 'gamma': 0.08892697565225295, 'reg_alpha': 0.8088487657690534, 'reg_lambda': 1.4389006939688471}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:04:38] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:04:53] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:05:08] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 23:05:22,738] Trial 38 finished with value: 0.9553548623525208 and parameters: {'learning_rate': 0.07507422400051636, 'max_depth': 4, 'subsample': 0.761489764829394, 'colsample_bytree': 0.7061283522884679, 'min_child_weight': 3, 'gamma': 0.136342266851064, 'reg_alpha': 0.8941771474978472, 'reg_lambda': 1.442090971352548}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:05:23] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:05:37] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:05:51] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 23:06:05,738] Trial 39 finished with value: 0.9554259921883679 and parameters: {'learning_rate': 0.11969468343323712, 'max_depth': 4, 'subsample': 0.8497427269586857, 'colsample_bytree': 0.563896207256299, 'min_child_weight': 4, 'gamma': 0.09042688101161053, 'reg_alpha': 0.8008079209376017, 'reg_lambda': 1.1329043768688614}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:06:06] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:06:25] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:06:44] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 23:07:03,070] Trial 40 finished with value: 0.9553395254229091 and parameters: {'learning_rate': 0.05793273147664574, 'max_depth': 6, 'subsample': 0.8592443933426026, 'colsample_bytree': 0.560943542274898, 'min_child_weight': 4, 'gamma': 0.08138730466349878, 'reg_alpha': 0.8204856734733335, 'reg_lambda': 1.1340477305810492}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:07:03] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:07:16] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:07:30] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 23:07:43,595] Trial 41 finished with value: 0.9554231045713099 and parameters: {'learning_rate': 0.12117818107481396, 'max_depth': 3, 'subsample': 0.7952268983040083, 'colsample_bytree': 0.5813729768122389, 'min_child_weight': 3, 'gamma': 0.20623508199101062, 'reg_alpha': 0.9898869977785961, 'reg_lambda': 1.4204437579672038}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:07:44] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:07:59] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:08:14] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 23:08:28,794] Trial 42 finished with value: 0.9554355062275267 and parameters: {'learning_rate': 0.12068010118536161, 'max_depth': 4, 'subsample': 0.79480986811973, 'colsample_bytree': 0.5293724687938388, 'min_child_weight': 2, 'gamma': 0.254862207415341, 'reg_alpha': 0.9498540362968867, 'reg_lambda': 1.4693736862771063}. Best is trial 15 with value: 0.9554431031835063.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:08:29] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:08:44] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:08:59] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 23:09:13,904] Trial 43 finished with value: 0.9554486589639611 and parameters: {'learning_rate': 0.0952111428362138, 'max_depth': 4, 'subsample': 0.7897794373707813, 'colsample_bytree': 0.5150028289211498, 'min_child_weight': 2, 'gamma': 0.2945155736818904, 'reg_alpha': 0.9925804098627933, 'reg_lambda': 1.4247040793809762}. Best is trial 43 with value: 0.9554486589639611.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:09:14] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:09:30] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:09:45] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 23:10:01,140] Trial 44 finished with value: 0.9554092673565006 and parameters: {'learning_rate': 0.09297100969902852, 'max_depth': 5, 'subsample': 0.9078539243867702, 'colsample_bytree': 0.521378198956265, 'min_child_weight': 2, 'gamma': 0.28429749741391513, 'reg_alpha': 0.9965264022138369, 'reg_lambda': 1.5976896830242513}. Best is trial 43 with value: 0.9554486589639611.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:10:01] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:10:16] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:10:31] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 23:10:47,461] Trial 45 finished with value: 0.9554452940945346 and parameters: {'learning_rate': 0.11357638179051625, 'max_depth': 4, 'subsample': 0.7949065998025835, 'colsample_bytree': 0.5347707431256783, 'min_child_weight': 2, 'gamma': 0.3455847972510597, 'reg_alpha': 0.9488397134615066, 'reg_lambda': 1.0012237684240977}. Best is trial 43 with value: 0.9554486589639611.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:10:48] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:11:02] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:11:16] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 23:11:30,220] Trial 46 finished with value: 0.9554550620655022 and parameters: {'learning_rate': 0.10796297366057209, 'max_depth': 4, 'subsample': 0.8209812937137574, 'colsample_bytree': 0.503646232629211, 'min_child_weight': 2, 'gamma': 0.40319071874163315, 'reg_alpha': 0.9284337490805418, 'reg_lambda': 1.0334018678509929}. Best is trial 46 with value: 0.9554550620655022.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:11:30] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:11:46] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:12:02] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 23:12:18,639] Trial 47 finished with value: 0.9553713163810537 and parameters: {'learning_rate': 0.1024878169839392, 'max_depth': 5, 'subsample': 0.8328685351771461, 'colsample_bytree': 0.5080273548410206, 'min_child_weight': 2, 'gamma': 0.4127332150369115, 'reg_alpha': 0.9462618076915268, 'reg_lambda': 1.0198303622154592}. Best is trial 46 with value: 0.9554550620655022.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:12:19] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:12:38] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:12:57] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 23:13:14,760] Trial 48 finished with value: 0.9552488804314612 and parameters: {'learning_rate': 0.082316506559616, 'max_depth': 6, 'subsample': 0.7831819016180344, 'colsample_bytree': 0.5347079370073213, 'min_child_weight': 1, 'gamma': 0.3615017398702217, 'reg_alpha': 0.9364182239303582, 'reg_lambda': 1.000939049161914}. Best is trial 46 with value: 0.9554550620655022.\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:13:15] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:13:32] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:200: UserWarning: [23:13:51] WARNING: /__w/xgboost/xgboost/src/learner.cc:782: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "[I 2026-02-20 23:14:07,585] Trial 49 finished with value: 0.955414662504206 and parameters: {'learning_rate': 0.06093489824025706, 'max_depth': 5, 'subsample': 0.7469109867133928, 'colsample_bytree': 0.5003210245902793, 'min_child_weight': 1, 'gamma': 0.3319996999420828, 'reg_alpha': 0.9204487215863845, 'reg_lambda': 1.5199400481279663}. Best is trial 46 with value: 0.9554550620655022.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'learning_rate': 0.10796297366057209, 'max_depth': 4, 'subsample': 0.8209812937137574, 'colsample_bytree': 0.503646232629211, 'min_child_weight': 2, 'gamma': 0.40319071874163315, 'reg_alpha': 0.9284337490805418, 'reg_lambda': 1.0334018678509929}\n",
            "Best CV: 0.95546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = study.best_params.copy()\n",
        "best_params.pop('n_estimators', None)\n",
        "best_params['n_estimators'] = 1000  # we'll use early stopping to find optimal number\n",
        "\n",
        "final_model = xgb.XGBClassifier(\n",
        "    **best_params,\n",
        "    early_stopping_rounds=50,\n",
        "    eval_metric='auc',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# We need an eval_set for early stopping ‚Äî split a small validation set from training\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
        "\n",
        "final_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "print(f\"Best iteration: {final_model.best_iteration}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2TcUffUCkH6",
        "outputId": "6722c2ca-c493-476f-b995-398f4a12639e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best iteration: 430\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove n_estimators from best_params so we can pass it separately\n",
        "params_for_final = best_params.copy()\n",
        "params_for_final.pop('n_estimators', None)   # delete if present\n",
        "\n",
        "final_model_full = xgb.XGBClassifier(\n",
        "    **params_for_final,\n",
        "    n_estimators=final_model.best_iteration,  # use the optimal number found\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "final_model_full.fit(X, y)\n",
        "\n",
        "test_preds = final_model_full.predict_proba(X_test)[:, 1]\n",
        "\n",
        "submission = pd.DataFrame({'id': test_ids, 'Heart Disease': test_preds})\n",
        "submission.to_csv('optuna_tuned_submission.csv', index=False)\n",
        "\n",
        "from google.colab import files\n",
        "files.download('optuna_tuned_submission.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "PUsnxrCRCzaH",
        "outputId": "9bc21be9-597f-4bfa-e5b1-3f9f1d31fc63"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_439e3560-6efb-4d3e-badf-ea4f701a81d3\", \"optuna_tuned_submission.csv\", 4853749)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}